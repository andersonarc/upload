# ðŸ”§ Complete Fix Guide: SpiNNaker V1 Cortex Debugging

**Date**: 2025-11-10
**Session**: Autonomous debug session results
**Branch**: `claude/debug-spinnaker-inference-011CUxkRXvCZjSAaZ55GDpnk`

---

## ðŸŽ¯ Bugs Identified

### Bug #1: ASC Scaling Error âœ… CONFIRMED
**File**: `jupyter/class.py` lines 123-124
**Status**: User confirmed ASC values are unnormalized
**Severity**: ðŸ”´ CRITICAL - ASC amplitudes 15-25x too large

### Bug #2: LGN Grouping Error ðŸ”´ FOUND
**File**: `jupyter/class.py` lines 664-666
**Status**: Code analysis confirmed
**Severity**: ðŸ”´ CRITICAL - Wrong LGNâ†’V1 connectivity

### Bug #3: Weight Scaling Error âš ï¸ UNCERTAIN
**File**: `jupyter/class.py` lines 841, 888
**Status**: Depends on H5 file format (likely same issue as ASC)
**Severity**: âš ï¸ HIGH - If H5 has unnormalized weights

---

## ðŸ”§ Fix #1: ASC Scaling (CONFIRMED)

**Problem**: After-spike currents multiplied by voltage_scale when they shouldn't be

**Current Code** (lines 123-124):
```python
network['glif3'][:, G.AA0] *= network['glif3'][:, G.VSC] / 1000.0
network['glif3'][:, G.AA1] *= network['glif3'][:, G.VSC] / 1000.0
```

**Fixed Code**:
```python
network['glif3'][:, G.AA0] /= 1000.0  # pA -> nA (no voltage_scale!)
network['glif3'][:, G.AA1] /= 1000.0  # pA -> nA (no voltage_scale!)
```

**Explanation**:
- H5 file stores ASC in pA (unnormalized)
- Should convert: pA / 1000 = nA
- Was doing: pA * voltage_scale / 1000 (20x too large)

---

## ðŸ”§ Fix #2: LGN Grouping (CRITICAL)

**Problem**: `lgn_group_similar()` merges LGN neurons with different connectivity

**Current Code** (lines 664-666):
```python
tm2l_1, l2pl_1 = lgn_group_similar(t2l, threshold=0.15)
tm2l_2, l2pl_2 = lgn_group_similar(tm2l_1, threshold=0.15)
tm2l, l2pl = lgn_group_similar(tm2l_2, threshold=0.15)
```

**Fixed Code** - Option A (Quick Fix):
```python
# Comment out merging, use exact grouping only
# tm2l_1, l2pl_1 = lgn_group_similar(t2l, threshold=0.15)
# tm2l_2, l2pl_2 = lgn_group_similar(tm2l_1, threshold=0.15)
# tm2l, l2pl = lgn_group_similar(tm2l_2, threshold=0.15)

# Use exact grouping (no merging)
tm2l = t2l
l2pl = {}
for lgn_gid in range(17400):  # 17400 LGN neurons
    # Find which target group this LGN belongs to
    if lgn_gid not in l2t:
        continue  # Skip if no connections
    tgtkey = tuple(sorted(l2t[lgn_gid]))

    # Find or create population for this target set
    if tgtkey not in tm2l:
        tm2l[tgtkey] = []
    lgn_pid = list(tm2l.keys()).index(tgtkey)
    lgn_lid = len(tm2l[tgtkey])
    tm2l[tgtkey].append(lgn_gid)
    l2pl[lgn_gid] = (lgn_pid, lgn_lid)
```

**Fixed Code** - Option B (Better, but more changes):
```python
# Use threshold=0.0 for exact matching
tm2l_1, l2pl_1 = lgn_group_similar(t2l, threshold=0.0)
tm2l_2, l2pl_2 = lgn_group_similar(tm2l_1, threshold=0.0)
tm2l, l2pl = lgn_group_similar(tm2l_2, threshold=0.0)
```

**Explanation**:
- Original code merges LGN neurons with "similar" targets (15% difference)
- But PyNN Population broadcasts spikes to ALL neurons in population
- Result: LGN neurons activate V1 neurons they're not connected to
- Fix: Only group LGN neurons with EXACTLY the same connectivity

**Trade-off**:
- More LGN populations (higher memory)
- But correct connectivity (required for function)

---

## ðŸ”§ Fix #3: Weight Scaling (IF NEEDED)

**Problem**: Weights multiplied by voltage_scale when they might already be normalized

**Current Code** (lines 841, 888):
```python
vsc = network['glif3'][int(tgt_key[0]), G.VSC]
syn[:, S.WHT] *= vsc / 1000.0
```

**Fixed Code** (IF H5 has unnormalized weights):
```python
# vsc = network['glif3'][int(tgt_key[0]), G.VSC]
syn[:, S.WHT] /= 1000.0  # pA -> nA (no voltage_scale!)
```

**How to know if fix needed**:

**Option A**: Check c2.py conversion logs
```bash
grep "Using TRAINED\|Using UNTRAINED" /path/to/c2_conversion.log
```
- If "Using TRAINED": Weights normalized â†’ Keep current code
- If "Using UNTRAINED": Weights unnormalized â†’ Apply fix

**Option B**: Test empirically
1. Apply ASC and LGN fixes
2. Test with current weight scaling
3. If still failing, apply weight fix
4. Compare accuracy

**Option C**: Inspect H5 file (requires working file)
```bash
python jupyter/verify_asc_normalization.py
# Will show if values are normalized or not
```

---

## ðŸ“ Complete Patch File

**File**: `jupyter/class.py`

**Changes needed**:

```diff
@@ -120,8 +120,8 @@
         network['glif3'][:, G.CM]  /= 1000.0 # pF -> nF
         network['glif3'][:, G.G]   /= 1000.0 # nS -> uS
         network['glif3'][:, G.VSC] = network['glif3'][:, G.THR] - network['glif3'][:, G.EL] # voltage scale
-        network['glif3'][:, G.AA0] *= network['glif3'][:, G.VSC] / 1000.0 # pA -> nA
-        network['glif3'][:, G.AA1] *= network['glif3'][:, G.VSC] / 1000.0 # pA -> nA
+        network['glif3'][:, G.AA0] /= 1000.0 # pA -> nA (FIXED: removed voltage_scale)
+        network['glif3'][:, G.AA1] /= 1000.0 # pA -> nA (FIXED: removed voltage_scale)

@@ -661,9 +661,10 @@
 # And again.
-tm2l_1, l2pl_1 = lgn_group_similar(t2l, threshold=0.15)
-tm2l_2, l2pl_2 = lgn_group_similar(tm2l_1, threshold=0.15)
-tm2l, l2pl = lgn_group_similar(tm2l_2, threshold=0.15)
+# FIXED: Disabled LGN merging to preserve exact connectivity
+tm2l_1, l2pl_1 = lgn_group_similar(t2l, threshold=0.0)  # Exact matching only
+tm2l_2, l2pl_2 = lgn_group_similar(tm2l_1, threshold=0.0)
+tm2l, l2pl = lgn_group_similar(tm2l_2, threshold=0.0)

# IF weight fix needed (check first!):
@@ -838,7 +838,7 @@
         # Scale
         vsc = network['glif3'][int(tgt_key[0]), G.VSC]
-        syn[:, S.WHT] *= vsc / 1000.0
+        syn[:, S.WHT] /= 1000.0  # FIXED: removed voltage_scale (if weights unnormalized)
         if p < 5:
             print(vsc)

@@ -885,7 +885,7 @@
         # Scale
         vsc = network['glif3'][int(tgt_key[0]), G.VSC]
-        syn[:, S.WHT] *= vsc / 1000.0
+        syn[:, S.WHT] /= 1000.0  # FIXED: removed voltage_scale (if weights unnormalized)
```

---

## ðŸ§ª Testing Protocol

### Test 1: ASC + LGN Fixes Only (Recommended First)

1. Apply ASC fix (lines 123-124)
2. Apply LGN fix (lines 664-666)
3. Run SpiNNaker inference
4. Check accuracy

**Expected outcome**:
- If weights are trained (normalized): Should achieve ~80% accuracy
- If weights are untrained/unnormalized: May still have issues

### Test 2: Add Weight Fix If Needed

If Test 1 shows partial improvement but not full:
1. Apply weight fix (lines 841, 888)
2. Run inference again
3. Check accuracy

**Expected outcome**: Should achieve ~80% accuracy (matching TensorFlow)

### Test 3: Verify Individual Bug Impact

To isolate which bug has most impact:
1. Test with ONLY ASC fix
2. Test with ONLY LGN fix
3. Test with ONLY weight fix
4. Test with ALL fixes

Compare accuracy to understand individual contributions.

---

## ðŸ“Š Expected Results

| Configuration | Expected Accuracy | Notes |
|--------------|-------------------|-------|
| **No fixes** | 0% | Current state (garbage/silence) |
| **ASC only** | 10-30% | Reduces post-spike chaos |
| **LGN only** | 20-40% | Fixes input connectivity |
| **Weights only** | 10-30% | Fixes synaptic strength (if needed) |
| **ASC + LGN** | 60-70% | Major improvement expected |
| **All fixes** | **~80%** | Should match TensorFlow |

---

## ðŸŽ¯ Priority Order

1. **ASC fix** (100% confirmed bug)
2. **LGN fix** (90% confident, critical impact)
3. **Weight fix** (50% confident, apply if needed)

---

## ðŸ“‹ Verification Scripts Available

1. **`jupyter/verify_asc_normalization.py`** - Check ASC and weight formats in H5
2. **`jupyter/check_h5_weights.py`** - Full H5 weight diagnostics
3. **`training_code/visualize_weight_heatmaps.py`** - Compare TF vs H5 vs untrained
4. **`jupyter/verify_pp_routing_preservation.py`** - Verify PP routing correctness

---

## ðŸ’¬ Summary for User

Found **3 CRITICAL BUGS**:

1. **ASC scaling** (CONFIRMED by you) - 20x too large
2. **LGN grouping** (FOUND by me) - Wrong connectivity
3. **Weight scaling** (LIKELY) - Same issue as ASC

**Immediate action**: Apply fixes #1 and #2, test. If still failing, apply #3.

**Expected outcome**: 0% â†’ 80% accuracy after all fixes.

All analysis documents and verification scripts committed to branch.
