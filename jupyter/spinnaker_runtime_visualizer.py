#!/usr/bin/env python3
"""
SpiNNaker Runtime Visualization

Purpose: Analyze SpiNNaker network activity and compare with TensorFlow.

Analyzes:
1. Input: LGN spike times (verify Poisson sampling)
2. V1 Activities: Population-level spike rates
3. Output: Readout neuron spikes and predictions

Requires:
- class.py to be modified to record all V1 populations
- OR analyze existing spike recordings from output

Visualizations:
- LGN spike rasters
- V1 population activity traces
- Output spike rasters
- Side-by-side comparison with TensorFlow
"""

import numpy as np
import matplotlib.pyplot as plt
import h5py
import pickle as pkl
import sys
from collections import defaultdict

print("=" * 80)
print("SpiNNaker Runtime Visualization")
print("=" * 80)

# Configuration
SPIKES_FILE = 'spikes-128.h5'  # LGN input probabilities
SPINNAKER_OUTPUT = 'spinnaker_output_spikes.pkl'  # Generated by modified class.py
TEST_SAMPLES = [10, 50, 90, 100]
SIMULATION_TIME = 100.0  # ms
RESPONSE_WINDOW = (50.0, 100.0)  # ms
SEED = 1

# =============================================================================
# Step 1: Load LGN spike probabilities
# =============================================================================

print("\nStep 1: Loading LGN spike probabilities...")

try:
    with h5py.File(SPIKES_FILE, 'r') as f:
        spike_probs = np.array(f['spikes'])  # (128, 100, 17400)

    print(f"  ✓ Loaded spike probabilities: {spike_probs.shape}")
    print(f"    (samples, timesteps, lgn_neurons)")

except FileNotFoundError:
    print(f"ERROR: Spikes file not found: {SPIKES_FILE}")
    print("Please download from HuggingFace repository")
    sys.exit(1)

# =============================================================================
# Step 2: Regenerate LGN spike trains (same as class.py)
# =============================================================================

print("\nStep 2: Regenerating LGN spike trains...")

def generate_lgn_spikes(spike_probs, sample_idx, seed=SEED, timestep=1.0):
    """Generate LGN spike trains using same logic as class.py"""
    np.random.seed(seed)

    lgn_size = spike_probs.shape[2]
    spike_times = []

    for lgn_i in range(lgn_size):
        times = []
        for t in range(spike_probs.shape[1]):
            # Same as class.py line 274
            prob = np.clip((spike_probs[sample_idx, t, lgn_i] / 1.3), 0.0, 1.0)
            if prob > np.random.rand():
                times.append(float(t * timestep))

        spike_times.append(times if len(times) > 0 else [])

    return spike_times

lgn_spikes_by_sample = {}
for sample_idx in TEST_SAMPLES:
    spike_times = generate_lgn_spikes(spike_probs, sample_idx)
    lgn_spikes_by_sample[sample_idx] = spike_times

    # Statistics
    total_spikes = sum(len(times) for times in spike_times)
    avg_rate = total_spikes / (17400 * 100 / 1000)  # Hz

    print(f"  Sample {sample_idx}: {total_spikes} LGN spikes, {avg_rate:.2f} Hz avg")

# =============================================================================
# Step 3: Load SpiNNaker output spikes
# =============================================================================

print("\nStep 3: Loading SpiNNaker output spikes...")

# NOTE: This requires class.py to save spike data
# For now, create a placeholder that shows what to expect

print("  ⚠️  This requires modified class.py to record spikes")
print("  Placeholder implementation showing expected data format:")

# Expected format:
spinnaker_results = {
    'samples': {},
    'v1_populations': ['E_L23', 'I_L23', 'E_L4', 'I_L4', 'E_L5', 'I_L5', 'E_L6', 'I_L6'],
    'output_neurons': list(range(300)),
    'simulation_time': SIMULATION_TIME
}

# Placeholder data structure
for sample_idx in TEST_SAMPLES:
    spinnaker_results['samples'][sample_idx] = {
        'lgn_spikes': lgn_spikes_by_sample[sample_idx],  # LGN input
        'v1_spikes': {},  # V1 population spikes (needs recording)
        'output_spikes': defaultdict(list),  # Output neuron spikes
        'predicted_class': None,  # Decoded prediction
        'votes': np.zeros(10)  # Vote distribution
    }

print(f"  Expected data format prepared")
print(f"  To enable this, modify class.py to record V1 populations:")
print(f"    - After creating each V1 population, call .record(['spikes'])")
print(f"    - Save spike data using pickle after simulation")

# =============================================================================
# Step 4: Mock visualization (shows what real visualization would look like)
# =============================================================================

print("\nStep 4: Creating visualizations...")

fig = plt.figure(figsize=(18, 12))
gs = fig.add_gridspec(len(TEST_SAMPLES), 4, hspace=0.3, wspace=0.3)

for row, sample_idx in enumerate(TEST_SAMPLES):
    lgn_spikes = lgn_spikes_by_sample[sample_idx]

    # Plot 1: LGN spike raster (sample of neurons)
    ax = fig.add_subplot(gs[row, 0])

    # Sample 100 neurons for visualization
    sample_neurons = np.linspace(0, 17400, 100, dtype=int)
    for i, neuron_idx in enumerate(sample_neurons):
        times = lgn_spikes[neuron_idx]
        ax.plot(times, [i] * len(times), 'k.', markersize=1)

    ax.set_xlim(0, SIMULATION_TIME)
    ax.set_ylim(0, 100)
    ax.set_ylabel('Neuron (sample)')
    if row == 0:
        ax.set_title('LGN Input Raster')
    if row == len(TEST_SAMPLES) - 1:
        ax.set_xlabel('Time (ms)')
    ax.grid(True, alpha=0.2)

    # Add sample label
    ax.text(0.02, 0.95, f'Sample {sample_idx}',
            transform=ax.transAxes, va='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # Plot 2: LGN mean activity over time
    ax = fig.add_subplot(gs[row, 1])

    # Bin spikes into 1ms bins
    bins = np.arange(0, SIMULATION_TIME + 1, 1)
    spike_counts = np.zeros(len(bins) - 1)

    for times in lgn_spikes:
        counts, _ = np.histogram(times, bins=bins)
        spike_counts += counts

    spike_counts /= 17400  # Normalize by number of neurons

    ax.plot(bins[:-1], spike_counts, 'b-', linewidth=1)
    ax.set_xlim(0, SIMULATION_TIME)
    ax.set_ylim(0, spike_counts.max() * 1.1)
    if row == 0:
        ax.set_title('LGN Mean Activity')
    if row == len(TEST_SAMPLES) - 1:
        ax.set_xlabel('Time (ms)')
    ax.set_ylabel('Spikes/neuron/ms')
    ax.grid(True, alpha=0.3)

    # Plot 3: V1 population activities (PLACEHOLDER)
    ax = fig.add_subplot(gs[row, 2])

    # This would show actual V1 population spike rates
    # For now, show placeholder
    ax.text(0.5, 0.5, 'V1 Activity\n(needs recording)',
            ha='center', va='center', transform=ax.transAxes,
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))
    ax.set_xlim(0, SIMULATION_TIME)
    ax.set_ylim(0, 1)
    if row == 0:
        ax.set_title('V1 Population Activity')
    if row == len(TEST_SAMPLES) - 1:
        ax.set_xlabel('Time (ms)')
    ax.set_ylabel('Spike Rate (Hz)')
    ax.grid(True, alpha=0.3)

    # Plot 4: Output neuron spikes (PLACEHOLDER)
    ax = fig.add_subplot(gs[row, 3])

    # This would show actual output neuron spikes
    # For now, show placeholder
    ax.text(0.5, 0.5, 'Output Spikes\n(needs recording)',
            ha='center', va='center', transform=ax.transAxes,
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))
    ax.axvspan(RESPONSE_WINDOW[0], RESPONSE_WINDOW[1], alpha=0.2, color='green')
    ax.set_xlim(0, SIMULATION_TIME)
    ax.set_ylim(0, 300)
    if row == 0:
        ax.set_title('Output Neuron Raster')
    if row == len(TEST_SAMPLES) - 1:
        ax.set_xlabel('Time (ms)')
    ax.set_ylabel('Neuron ID')
    ax.grid(True, alpha=0.3)

plt.savefig('spinnaker_runtime_visualization.png', dpi=150)
print(f"  ✓ Saved visualization: spinnaker_runtime_visualization.png")

# =============================================================================
# Step 5: Comparison with TensorFlow (if available)
# =============================================================================

print("\nStep 5: Comparing with TensorFlow results...")

try:
    with open('tensorflow_results.pkl', 'rb') as f:
        tf_results = pkl.load(f)

    print(f"  ✓ Loaded TensorFlow results")

    # Create comparison plot
    fig, axes = plt.subplots(len(TEST_SAMPLES), 2, figsize=(12, 4 * len(TEST_SAMPLES)))

    for i, sample_idx in enumerate(TEST_SAMPLES):
        # Find matching TF result
        tf_result = next((r for r in tf_results if r['sample_idx'] == sample_idx), None)

        if tf_result is None:
            continue

        # Plot 1: LGN input comparison
        ax = axes[i, 0] if len(TEST_SAMPLES) > 1 else axes[0]

        # TensorFlow LGN input (continuous probabilities)
        tf_lgn = tf_result['lgn_input']
        ax.plot(np.mean(tf_lgn, axis=1), label='TensorFlow (prob)', linewidth=2)

        # SpiNNaker LGN spikes (convert to rate)
        lgn_spikes = lgn_spikes_by_sample[sample_idx]
        bins = np.arange(0, SIMULATION_TIME + 1, 1)
        spike_counts = np.zeros(len(bins) - 1)
        for times in lgn_spikes:
            counts, _ = np.histogram(times, bins=bins)
            spike_counts += counts
        spike_counts /= 17400

        ax.plot(bins[:-1], spike_counts, label='SpiNNaker (spikes)', alpha=0.7, linewidth=2)

        ax.set_title(f'Sample {sample_idx}: Input Comparison\n' +
                     f'TF: class={tf_result["predicted"]}, ' +
                     f'SpiNNaker: (needs output)')
        ax.set_xlabel('Time (ms)')
        ax.set_ylabel('Mean Activity')
        ax.legend()
        ax.grid(True, alpha=0.3)

        # Plot 2: Output comparison
        ax = axes[i, 1] if len(TEST_SAMPLES) > 1 else axes[1]

        # TensorFlow output
        tf_output = tf_result['output']
        for class_idx in range(10):
            linestyle = '-' if class_idx == tf_result['predicted'] else '--'
            ax.plot(tf_output[:, class_idx], label=f'TF Class {class_idx}',
                   linestyle=linestyle, alpha=0.5)

        ax.axvspan(RESPONSE_WINDOW[0], RESPONSE_WINDOW[1], alpha=0.2, color='green')
        ax.set_title(f'Output Comparison')
        ax.set_xlabel('Time (ms)')
        ax.set_ylabel('Activity')
        ax.legend(fontsize=8, ncol=2)
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('tensorflow_spinnaker_comparison.png', dpi=150)
    print(f"  ✓ Saved comparison: tensorflow_spinnaker_comparison.png")

except FileNotFoundError:
    print(f"  ⚠️  TensorFlow results not found")
    print(f"  Run tensorflow_runtime_visualizer.py first")

# =============================================================================
# Summary and Instructions
# =============================================================================

print("\n" + "=" * 80)
print("SpiNNaker Runtime Visualization Complete")
print("=" * 80)

print("\nGenerated files:")
print("  - spinnaker_runtime_visualization.png")
if 'tf_results' in locals():
    print("  - tensorflow_spinnaker_comparison.png")

print("\nTo enable full SpiNNaker activity recording:")
print("\n1. Modify class.py to record V1 populations:")
print("   After each 'V1.append(V1_x)' (around line 805), add:")
print("   ```")
print("   V1_x.record(['spikes'])")
print("   ```")

print("\n2. After simulation, save spike data:")
print("   ```python")
print("   import pickle")
print("   v1_spikes = {}")
print("   for i, pop in enumerate(V1):")
print("       v1_spikes[i] = pop.get_data('spikes')")
print("   ")
print("   with open('spinnaker_v1_spikes.pkl', 'wb') as f:")
print("       pickle.dump(v1_spikes, f)")
print("   ```")

print("\n3. Re-run this script to visualize full activity")

print("\nDiagnostic questions this visualization answers:")
print("  - Do LGN spikes match expected input?")
print("  - Do V1 populations show ANY activity?")
print("  - Do output neurons receive input?")
print("  - Where does SpiNNaker diverge from TensorFlow?")

print("\n" + "=" * 80)
